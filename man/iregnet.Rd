% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/iregnet.R
\name{iregnet}
\alias{iregnet}
\title{Fit interval censored AFT models with elastic net regularization}
\usage{
iregnet(x, y, family = c("gaussian", "logistic", "loggaussian",
  "loglogistic", "extreme_value", "exponential", "weibull"), alpha = 1,
  lambda = NULL, num_lambda = 100, intercept = TRUE,
  standardize = TRUE, scale_init = NA, estimate_scale = TRUE,
  maxiter = 1000, threshold = 0.001, unreg_sol = TRUE,
  eps_lambda = NA, debug = 1)
}
\arguments{
\item{x}{Input matrix of covariates with dimension n_obs * n_vars, with
\eqn{nvars \ge 2}. Sparse matrices are not supported.}

\item{y}{Response variable. It can take two forms: \itemize{
\item 2 column real matrix with NAs denoting a censored observation
\item \code{\link{Surv}} object. Supported \code{types} of \code{Surv}
are 'left', 'right', 'interval' and 'interval2'.
}}

\item{family}{The distribution to fit. It can be one of "gaussian", "logistic",
"loggaussian", "loglogistic", "extreme_value", "exponential". Partial matching
is allowed.
\cr \emph{Default: "gaussian"}}

\item{alpha}{Elastic net mixing parameter, with \eqn{0 \le \alpha \le 1}. The
elastic net penalty is defined as in \code{glmnet}:
\deqn{0.5 * (1-\alpha) \|\beta\|_2^2 | + \alpha \|\beta\|_1}
alpha=1 is the lasso penalty, and alpha=0 is ridge penalty.
\cr \emph{Default: 1}}

\item{lambda}{Vector containing the path of \strong{decreasing} regularization
parameter lambda values. \cr If not supplied, the function will calculate a
lambda path of length \code{num_lambda} itself. \strong{NOTE:} The lambda
values are scaled because of the nuisance parameter, and hence not directly
comparable to those of other packages like \code{glmnet}.
\cr \emph{Default: \code{NA}}}

\item{num_lambda}{The number of lambda values calculated by the function.
Ignored if \code{lambda} is supplied by the user.
\cr \emph{Default: 100}}

\item{intercept}{\code{TRUE} if an intercept is to be fit, otherwise
\code{FALSE}. Intercept is calculated by appending a column of 1s to \code{x}.
\cr \emph{Default: \code{TRUE}}}

\item{standardize}{\code{TRUE} if \code{x} must be standardized before fit,
otherwise \code{FALSE}. Calculated \code{beta} are scaled to original scale
before returning.
\cr \emph{Default: \code{TRUE}}}

\item{scale_init}{Initial value of the scale parameter to use. If not supplied,
a suitable value is calculated depending on the distribution.
\cr \emph{Default: NA}}

\item{estimate_scale}{\code{TRUE} if \code{scale} is to be estimated. To
use a fixed value \code{scale0} for \code{scale}, set \code{scale_init=scale0
, estimate_scale=FALSE}. \emph{See examples.}
\cr \emph{Default: \code{TRUE}}}

\item{maxiter}{Maximum number of iterations over data per lambda value.
\cr \emph{Default: 1e3}}

\item{threshold}{The convergence threshold for coordinate descent. The inner
loop continues until the absolute update in each parameter is greater than
\code{threshold}.
\cr \emph{Default: 1e-4}}

\item{unreg_sol}{\code{TRUE} if the final solution computed must be
unregularized. Overwritten to \code{FALSE} if n_vars > n_obs.
Only used if \code{lambda_path} is not specified.
\cr \emph{Default: \code{TRUE}}}

\item{eps_lambda}{The ratio of the minimum value of \code{lambda} to the
(calculated) maximum value, in case no lambda is supplied. \code{num_lambda}
\code{lambda} values are calculated between \code{lambda_max} and
\code{lambda_min} on the log scale.
\cr \emph{Default: 0.0001 if n_vars < n_obs, 0.1 otherwise.}}

\item{debug}{\code{TRUE} if code debugging messages must be printed.
\cr \emph{Default: \code{FALSE}}}
}
\value{
Returns a S3 object iregnet with the following elements:\cr
\tabular{ll}{
 \code{beta} \tab Matrix of size \code{(n_vars+1) * num_lambda} containing
 intercept, coefficients of \code{X} for each \code{lambda} in the fit model.
   \cr
 \code{call} \tab Copy of the call that produced this object. \cr
 \code{lambda} \tab Vector of size \code{num_lambda} of (calculated or
  supplied) regularization parameter \code{lambda} values. \cr
 \code{loglik} \tab Vector of size \code{num_lambda} of log-likelihoods of
   the fit at each \code{lambda} value, excluding the contribution of the
   penalty terms. \cr
 \code{num_lambda} \tab Number of \code{lambda} values. \cr
 \code{n_iters} \tab Vector of size \code{num_lambda} of number of iterations
   taken at each \code{lambda}. \cr
 \code{scale} \tab Vector of size \code{num_lambda} of estimated
   scale at each \code{lambda} value, if \code{estimate_scale == TRUE}. Same as
   \code{scale_init} otherwise. \cr
 \code{scale_init} \tab Initial value (calculated or supplied) of \code{scale}. \cr
 \code{estimate_scale} \tab \code{TRUE} if the \code{scale} was estimated. \cr
 \code{error_status} \tab The error status. \code{0} denotes no errors.
   \code{-1} denotes that convergence was not reached in \code{maxiter}. \cr
}
}
\description{
Fit accelerated failure time models using interval censored data via
elastic net penalized maximum likeihood. Solutions are computed using
coordinate descent for a path of values of the regularization parameter
lambda. Supports gaussian, logistic and extreme value distributions.
}
\details{
At each regularization parater value \code{lambda}, cyclic coordinate
descent is used to update the parameters until convergence. The intercept and
the scale parameter are never regularized.
The obtained solution is used to initialize the parameters at the next \code{
lambda} value.
}
\section{References}{

Friedman, J., Hastie, T. and Tibshirani, R. (2008) Regularization Paths for
Generalized Linear Models via Coordinate Descent,
\url{http://www.stanford.edu/~hastie/Papers/glmnet.pdf}

Simon, N., Friedman, J., Hastie, T., Tibshirani, R. (2011) Regularization
Paths for Cox's Proportional Hazards Model via Coordinate Descent, Journal
of Statistical Software, Vol. 39(5) 1-13
\url{http://www.jstatsoft.org/v39/i05/}
}

\examples{
# y can be a 2 column matrix.
set.seed(10)
X <- matrix(rnorm(50), 10, 5)
y <- matrix(rnorm(20), 10, 2)
y <- t(apply(y, 1, sort)) # intervals must be non-decreasing
fit1 <- iregnet(X, y)

# Surv objects from survival are also supported.
data("ovarian", package="survival")
library(survival)
X <- cbind(ovarian$ecog.ps, ovarian$rx)
y <- Surv(ovarian$futime, ovarian$fustat)
fit2 <- iregnet(X, y)

# Log-Gaussian is same as Gaussian with log-transformed data
X <- cbind(ovarian$ecog.ps, ovarian$rx)
y <- Surv(ovarian$futime, ovarian$fustat)
y_log <- Surv(log(ovarian$futime), ovarian$fustat)
fit3 <- iregnet(X, y_log, "gaussian", threshold=1e-2)
fit4 <- iregnet(X, y, "loggaussian", threshold=1e-2)

# Scale parameter can be fixed by setting the estimate_scale flag.
set.seed(10)
X <- matrix(rnorm(50), 10, 5)
y <- matrix(rnorm(20), 10, 2)
y <- t(apply(y, 1, sort)) # intervals must be non-decreasing
fit5 <- iregnet(X, y, scale_init=1, estimate_scale=FALSE)

}
\seealso{
\code{\link{predict.iregnet}}, \code{cv.iregnet}, \code{\link{plot.iregnet}}
}
\author{
Anuj Khare, Toby Dylan Hocking, Jelle Goeman. \cr
Maintainer: Anuj Khare \email{khareanuj18@gmail.com}
}
